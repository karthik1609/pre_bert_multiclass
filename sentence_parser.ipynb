{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.attrs import *\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from spacy import attrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = 'The condition of the bike was poor but the service is easy on the wallet'\n",
    "doc = nlp(comment)\n",
    "data = sorted([(token.head.i, token.i, token, token.head, (token.head.pos_=='AUX'), (token.head.pos_==token.pos_ and not token.head.i == token.i)) for token in doc], key=lambda x: x[0], reverse=False)\n",
    "df = pd.DataFrame(data, columns =['token head index', 'token index', 'token', 'token head', 'Is token AUX?', 'is token ready for cutoff?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token head index</th>\n",
       "      <th>token index</th>\n",
       "      <th>token</th>\n",
       "      <th>token head</th>\n",
       "      <th>Is token AUX?</th>\n",
       "      <th>is token ready for cutoff?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>condition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>condition</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>bike</td>\n",
       "      <td>of</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>bike</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>condition</td>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>but</td>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>is</td>\n",
       "      <td>was</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>the</td>\n",
       "      <td>service</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>service</td>\n",
       "      <td>is</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>easy</td>\n",
       "      <td>is</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>on</td>\n",
       "      <td>easy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>wallet</td>\n",
       "      <td>on</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>the</td>\n",
       "      <td>wallet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token head index  token index      token token head  Is token AUX?  \\\n",
       "0                  1            0        The  condition          False   \n",
       "1                  1            2         of  condition          False   \n",
       "2                  2            4       bike         of          False   \n",
       "3                  4            3        the       bike          False   \n",
       "4                  5            1  condition        was           True   \n",
       "5                  5            5        was        was           True   \n",
       "6                  5            6       poor        was           True   \n",
       "7                  5            7        but        was           True   \n",
       "8                  5           10         is        was           True   \n",
       "9                  9            8        the    service          False   \n",
       "10                10            9    service         is           True   \n",
       "11                10           11       easy         is           True   \n",
       "12                11           12         on       easy          False   \n",
       "13                12           14     wallet         on          False   \n",
       "14                14           13        the     wallet          False   \n",
       "\n",
       "    is token ready for cutoff?  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "5                        False  \n",
       "6                        False  \n",
       "7                        False  \n",
       "8                         True  \n",
       "9                        False  \n",
       "10                       False  \n",
       "11                       False  \n",
       "12                       False  \n",
       "13                       False  \n",
       "14                       False  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = 'The bike was in poor condition but the service is easy on the wallet. Hyderabad is a city. Karthik is my name.'\n",
    "doc = nlp(comment)\n",
    "data = sorted([(token.head.i, token.i, token, token.head, (token.head.pos_=='AUX'), (token.head.pos_==token.pos_ and not token.head.i == token.i)) for token in doc], key=lambda x: x[0], reverse=False)\n",
    "df = pd.DataFrame(data, columns =['token head index', 'token index', 'token', 'token head', 'Is token connected to AUX?', 'is token ready for cutoff?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['is token ready for cutoff?'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,) DT det 1 True the (Hyderabad,) O \n",
      "(96,) NN nsubj 2 False bike (Hyderabad,) O \n",
      "(96,) VBD ROOT 2 False be (Hyderabad,) O \n",
      "(96,) IN prep 2 False in (Hyderabad,) O \n",
      "(96,) JJ amod 5 False poor (Hyderabad,) O \n",
      "(96,) NN pobj 3 False condition (Hyderabad,) O \n",
      "(96,) CC cc 2 False but (Hyderabad,) O \n",
      "(96,) DT det 8 False the (Hyderabad,) O \n",
      "(96,) NN nsubj 9 False service (Hyderabad,) O \n",
      "(96,) VBZ conj 2 False be (Hyderabad,) O \n",
      "(96,) JJ acomp 9 False easy (Hyderabad,) O \n",
      "(96,) IN prep 9 False on (Hyderabad,) O \n",
      "(96,) DT det 13 False the (Hyderabad,) O \n",
      "(96,) NN pobj 11 False wallet (Hyderabad,) O \n",
      "(96,) . punct 9 False . (Hyderabad,) O \n",
      "(96,) NNP nsubj 16 True Hyderabad (Hyderabad,) B GPE\n",
      "(96,) VBZ ROOT 16 False be (Hyderabad,) O \n",
      "(96,) DT det 18 False a (Hyderabad,) O \n",
      "(96,) NN attr 16 False city (Hyderabad,) O \n",
      "(96,) . punct 16 False . (Hyderabad,) O \n",
      "(96,) NNP nsubj 21 True Karthik (Hyderabad,) O \n",
      "(96,) VBZ ROOT 21 False be (Hyderabad,) O \n",
      "(96,) PRP$ poss 23 False my (Hyderabad,) O \n",
      "(96,) NN attr 21 False name (Hyderabad,) O \n",
      "(96,) . punct 21 False . (Hyderabad,) O \n"
     ]
    }
   ],
   "source": [
    "title_list = ['is conjunct?']\n",
    "for token in doc:\n",
    "    print(token.tensor.shape, token.tag_, token.dep_, token.head.i, token.is_sent_start, token.lemma_, doc.ents, token.ent_iob_, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.119121194"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = [token.vector for token in doc]\n",
    "np.dot(vecs[0], vecs[1]) / (np.dot(vecs[0], vecs[0]) + np.dot(vecs[1], vecs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_0: summary\n",
      "\t key_1: tok2vec\n",
      "\t\t {'assigns': ['doc.tensor'], 'requires': [], 'scores': [], 'retokenizes': False}\n",
      "\t key_1: tagger\n",
      "\t\t {'assigns': ['token.tag'], 'requires': [], 'scores': ['tag_acc'], 'retokenizes': False}\n",
      "\t key_1: parser\n",
      "\t\t {'assigns': ['token.dep', 'token.head', 'token.is_sent_start', 'doc.sents'], 'requires': [], 'scores': ['dep_uas', 'dep_las', 'dep_las_per_type', 'sents_p', 'sents_r', 'sents_f'], 'retokenizes': False}\n",
      "\t key_1: attribute_ruler\n",
      "\t\t {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}\n",
      "\t key_1: lemmatizer\n",
      "\t\t {'assigns': ['token.lemma'], 'requires': [], 'scores': ['lemma_acc'], 'retokenizes': False}\n",
      "\t key_1: ner\n",
      "\t\t {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'], 'requires': [], 'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'], 'retokenizes': False}\n",
      "key_0: problems\n",
      "\t key_1: tok2vec\n",
      "\t\t []\n",
      "\t key_1: tagger\n",
      "\t\t []\n",
      "\t key_1: parser\n",
      "\t\t []\n",
      "\t key_1: attribute_ruler\n",
      "\t\t []\n",
      "\t key_1: lemmatizer\n",
      "\t\t []\n",
      "\t key_1: ner\n",
      "\t\t []\n",
      "key_0: attrs\n",
      "\t key_1: token.head\n",
      "\t\t {'assigns': ['parser'], 'requires': []}\n",
      "\t key_1: token.dep\n",
      "\t\t {'assigns': ['parser'], 'requires': []}\n",
      "\t key_1: token.is_sent_start\n",
      "\t\t {'assigns': ['parser'], 'requires': []}\n",
      "\t key_1: token.ent_iob\n",
      "\t\t {'assigns': ['ner'], 'requires': []}\n",
      "\t key_1: token.tag\n",
      "\t\t {'assigns': ['tagger'], 'requires': []}\n",
      "\t key_1: doc.tensor\n",
      "\t\t {'assigns': ['tok2vec'], 'requires': []}\n",
      "\t key_1: token.lemma\n",
      "\t\t {'assigns': ['lemmatizer'], 'requires': []}\n",
      "\t key_1: doc.sents\n",
      "\t\t {'assigns': ['parser'], 'requires': []}\n",
      "\t key_1: doc.ents\n",
      "\t\t {'assigns': ['ner'], 'requires': []}\n",
      "\t key_1: token.ent_type\n",
      "\t\t {'assigns': ['ner'], 'requires': []}\n"
     ]
    }
   ],
   "source": [
    "for key in nlp.analyze_pipes().keys():\n",
    "    print('key_0:', key)\n",
    "    for key_ in nlp.analyze_pipes()[key].keys():\n",
    "        print('\\t', 'key_1:', key_)\n",
    "        print('\\t\\t', nlp.analyze_pipes()[key][key_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = dir(spacy.attrs)[:-12]\n",
    "list_.remove('IDS')\n",
    "list_.remove('NAMES')\n",
    "doc_gram_feats = doc.to_array(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "meaning_matrix = np.zeros((len(doc), len(doc)))\n",
    "for i in range(len(doc)):\n",
    "    for j in range(len(doc)):\n",
    "        meaning_matrix[i, j] = np.mean((doc_gram_feats[i] == doc_gram_feats[j])*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906976744186046"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(meaning_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the bike is a bike"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[-1].has_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.81395349, 0.81395349, 0.86046512, 0.79069767],\n",
       "       [0.81395349, 1.        , 0.81395349, 0.8255814 , 0.95348837],\n",
       "       [0.81395349, 0.81395349, 1.        , 0.8255814 , 0.80232558],\n",
       "       [0.86046512, 0.8255814 , 0.8255814 , 1.        , 0.80232558],\n",
       "       [0.79069767, 0.95348837, 0.80232558, 0.80232558, 1.        ]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meaning_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
