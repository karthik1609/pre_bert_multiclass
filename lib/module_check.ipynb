{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kr/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:52:10 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-14 13:52:10 INFO: Use device: cpu\n",
      "2022-02-14 13:52:10 INFO: Loading: tokenize\n",
      "2022-02-14 13:52:10 INFO: Loading: pos\n",
      "2022-02-14 13:52:10 INFO: Loading: lemma\n",
      "2022-02-14 13:52:10 INFO: Loading: depparse\n",
      "2022-02-14 13:52:10 INFO: Loading: sentiment\n",
      "2022-02-14 13:52:11 INFO: Loading: constituency\n",
      "2022-02-14 13:52:11 INFO: Loading: ner\n",
      "2022-02-14 13:52:11 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "phraser = preprocess.preprocess('Super')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phraser.phrase_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 11:16:54 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-11 11:16:54 INFO: Use device: gpu\n",
      "2022-02-11 11:16:54 INFO: Loading: tokenize\n",
      "2022-02-11 11:16:54 INFO: Loading: pos\n",
      "2022-02-11 11:16:54 INFO: Loading: lemma\n",
      "2022-02-11 11:16:54 INFO: Loading: depparse\n",
      "2022-02-11 11:16:54 INFO: Loading: sentiment\n",
      "2022-02-11 11:16:55 INFO: Loading: constituency\n",
      "2022-02-11 11:16:55 INFO: Loading: ner\n",
      "2022-02-11 11:16:55 INFO: Done loading processors!\n",
      "2022-02-11 11:16:55 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-11 11:16:55 INFO: Use device: gpu\n",
      "2022-02-11 11:16:55 INFO: Loading: tokenize\n",
      "2022-02-11 11:16:55 INFO: Loading: pos\n",
      "2022-02-11 11:16:55 INFO: Loading: lemma\n",
      "2022-02-11 11:16:55 INFO: Loading: depparse\n",
      "2022-02-11 11:16:56 INFO: Loading: sentiment\n",
      "2022-02-11 11:16:56 INFO: Loading: constituency\n",
      "2022-02-11 11:16:56 INFO: Loading: ner\n",
      "2022-02-11 11:16:56 INFO: Done loading processors!\n",
      "2022-02-11 11:16:56 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-11 11:16:56 INFO: Use device: gpu\n",
      "2022-02-11 11:16:56 INFO: Loading: tokenize\n",
      "2022-02-11 11:16:57 INFO: Loading: pos\n",
      "2022-02-11 11:16:57 INFO: Loading: lemma\n",
      "2022-02-11 11:16:57 INFO: Loading: depparse\n",
      "2022-02-11 11:16:57 INFO: Loading: sentiment\n",
      "2022-02-11 11:16:57 INFO: Loading: constituency\n",
      "2022-02-11 11:16:57 INFO: Loading: ner\n",
      "2022-02-11 11:16:58 INFO: Done loading processors!\n",
      "2022-02-11 11:16:58 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-11 11:16:58 INFO: Use device: gpu\n",
      "2022-02-11 11:16:58 INFO: Loading: tokenize\n",
      "2022-02-11 11:16:58 INFO: Loading: pos\n",
      "2022-02-11 11:16:58 INFO: Loading: lemma\n",
      "2022-02-11 11:16:58 INFO: Loading: depparse\n",
      "2022-02-11 11:16:58 INFO: Loading: sentiment\n",
      "2022-02-11 11:16:58 INFO: Loading: constituency\n",
      "2022-02-11 11:16:59 INFO: Loading: ner\n",
      "2022-02-11 11:16:59 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "sentiment_list = []\n",
    "for phrase in phraser.phrase_extract():\n",
    "    sentiment_list.append((phrase, preprocess.preprocess(phrase).sent_finder()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fat cat', 0.0),\n",
       " ('good cat', 0.7),\n",
       " ('bad car', -0.6999999999999998),\n",
       " ('red car', 0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
